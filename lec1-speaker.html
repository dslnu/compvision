<!DOCTYPE html>
<html lang="en"><head>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/tabby.min.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.42">

  <meta name="author" content="Vitaly Vlasov">
  <title>Computer Vision – Computer vision: intro</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="site_libs/revealjs/dist/theme/quarto-2f366650f320edcfcf53d73c80250a32.css">
  <link href="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-image="img/ar_street.jpg" data-background-opacity="0.1" data-background-size="contain" class="quarto-title-block center">
  <h1 class="title">Computer vision: intro</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Vitaly Vlasov 
</div>
        <p class="quarto-title-affiliation">
            Lviv University
          </p>
    </div>
</div>

</section>
<section>
<section id="history" class="title-slide slide level1 center">
<h1>History</h1>

</section>
<section id="euclid" class="slide level2">
<h2>Euclid</h2>
<p>Euclid (ca. 300 BCE): <strong>natural perspective</strong>: ray <strong>OP</strong> joining the center of projection <strong>O</strong> to the point <strong>P</strong>.</p>
<p><img data-src="img/euclid.jpg" height="500"></p>
</section>
<section id="aristotle" class="slide level2">
<h2>Aristotle</h2>
<p>Thought that eyes are <strong>emitting</strong> vision (<strong>emission theory</strong>). <img data-src="img/emission_theory.png" height="500"></p>
</section>
<section id="medieval" class="slide level2">
<h2>Medieval</h2>
<p>Ḥasan Ibn al-Haytham (<em>Alhazen</em>) - father of modern optics</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="img/Hazan.png" height="500"></p>
</div><div class="column" style="width:50%;">
<p><img data-src="img/alhazan_eye.jpg" height="500"></p>
</div></div>
</section>
<section id="renaissance" class="slide level2">
<h2>Renaissance</h2>
<h3 id="leon-battista-alberti">Leon Battista Alberti</h3>
<p><img data-src="img/alberti.jpg" height="360"></p>
<!-- In 1435, Alberti codified the rules and inspired generations of artists. -->
<blockquote>
<p>A truly universal genius (Jacob Burckhardt, The Civilization of the Renaissance in Italy)</p>
</blockquote>
</section>
<section id="descartes" class="slide level2">
<h2>Descartes</h2>
<h3 id="camera-eye">Camera eye</h3>
<p><img data-src="img/camera_eye.png" height="500"></p>
</section>
<section id="earlier-technologies" class="slide level2">
<h2>Earlier technologies</h2>
<div class="columns">
<div class="column" style="width:40%;">
<ul>
<li>camera obscura</li>
<li>the stereoscope</li>
<li>film photography</li>
</ul>
</div><div class="column" style="width:60%;">
<p><img data-src="img/camera_obscura.jpg" class="absolute" style="top: 60px; left: 500px; height: 320px; "> <img data-src="img/first_photo.jpg" class="absolute" style="top: 400px; left: 560px; height: 320px; "></p>
</div></div>
</section>
<section id="tank-detector" class="slide level2">
<h2>Tank Detector</h2>
<p><img data-src="img/tank_detector.png" height="500"></p>

<aside><div>
<p>Recognition system design by statistical analysis (https://dl.acm.org/doi/pdf/10.1145/800257.808903)</p>
</div></aside></section>
<section id="facial-recognition" class="slide level2">
<h2>Facial recognition</h2>
<p>Woody Bledsoe, Charles Bisson and Helen Chan: facial recognition for military (1964) <img data-src="img/rand_tablet.png" height="500"></p>
</section>
<section id="summer-vision-project" class="slide level2">
<h2>Summer Vision project</h2>
<!-- https://philippschmitt.com/archive/computer-vision-history/ -->
<!-- https://dspace.mit.edu/bitstream/handle/1721.1/6125/AIM-100.pdf?sequence=2 -->
<p><img data-src="img/summer_vision_project.png" height="500"></p>

<aside><div>
<p>Seymour Papert: https://dspace.mit.edu/bitstream/handle/1721.1/6125/AIM-100.pdf</p>
</div></aside></section>
<section id="summer-vision-project-1" class="slide level2">
<h2>Summer Vision project</h2>
<p>What was the plan? <strong>Divide and conquer</strong></p>
<h4 id="split-teams-doing-different-tasks">Split teams doing different tasks:</h4>
<div>
<ol type="1">
<li class="fragment">writing a program to detect edges, corners, and other pixel-level information</li>
<li class="fragment">forming continous shapes out of these low-level features</li>
<li class="fragment">arranging the shapes in three-dimensional space</li>
<li class="fragment">etc.</li>
</ol>
</div>
</section>
<section id="perceptron" class="slide level2">
<h2>Perceptron</h2>
<p>Frank Rosenblatt</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="img/perceptron_facial_recognition.png"></p>
</div><div class="column" style="width:50%;">
<p><img data-src="img/perceptron.jpg"></p>
</div></div>
</section>
<section id="generalized-cylinders" class="slide level2">
<h2>Generalized cylinders</h2>
<p>T.O. Binford (1970)</p>
<p><img data-src="img/binford_cylinders.jpg"></p>

<aside><div>
<p>Applied in Rodney Brooks’ ACRONYM (1981) - CIA aircraft detection</p>
</div></aside></section>
<section id="deformable-templates" class="slide level2">
<h2>Deformable templates</h2>
<p>Martin Fischler and Robert Elschlager (1972) <img data-src="img/deformable_templates.jpg" height="500"></p>
</section>
<section id="mobots" class="slide level2">
<h2>Mobots</h2>
<p>Rodney Brooks (1987): <em>perception as action</em></p>
<div class="columns">
<div class="column" height="400" style="width:50%;">
<p><img data-src="img/brooks_robots.png"></p>
</div><div class="column" height="400" style="width:50%;">
<p><img data-src="img/roomba.jpg"></p>
</div></div>
</section>
<section id="neocognitron" class="slide level2">
<h2>Neocognitron</h2>
<p><img data-src="img/neocognitron.png" height="450"></p>

<aside><div>
<p>Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position (https://www.rctn.org/bruno/public/papers/Fukushima1980.pdf)</p>
</div></aside></section>
<section id="lecun-cnn-paper" class="slide level2">
<h2>LeCun CNN paper</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="img/lecun_network1.png"></p>
</div><div class="column" style="width:50%;">
<p><img data-src="img/cnn_demo.png"></p>
</div></div>

<aside><div>
<p>Handwritten Digit Recognition with a Back-Propagation Network (https://proceedings.neurips.cc/paper/1989/file/53c3bce66e43be4f209556518c2fcb54-Paper.pdf)</p>
</div></aside></section></section>
<section>
<section id="concepts" class="title-slide slide level1 center">
<h1>Concepts</h1>

</section>
<section id="what-is-vision" class="slide level2">
<h2>What is vision?</h2>
<p>Vision is a perceptual channel that accepts a stimulus and reports some representation of the world. <img data-src="img/vision.jpeg" height="500"></p>
</section>
<section id="problem" class="slide level2">
<h2>Problem</h2>
<p>Azriel Rosenfeld, Picture Processing by Computer (1969)</p>
<blockquote>
<p>If we want to give our computers eyes, we must first give them an education in the facts of life.</p>
</blockquote>

<img data-src="img/education.jpg" class="r-stretch"></section>
<section id="sensing-types" class="slide level2">
<h2>Sensing types</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="passive">Passive</h3>
<p>Not sending out light to see.</p>
</div><div class="column" style="width:50%;">
<h3 id="active">Active</h3>
<p>Sending out a signal and sensing a reflection</p>
</div></div>
<p><img data-src="img/sensing_types.jpg" class="absolute" style="left: 160px; height: 400px; "></p>
</section>
<section id="active-sensing-examples" class="slide level2">
<h2>Active sensing examples</h2>
<ul>
<li>bats (<strong>ultrasound</strong>),</li>
<li>dolphins (<strong>sound</strong>)</li>
<li>abyssal fishes (<strong>light</strong>)</li>
<li>some robots (<strong>light, sound, radar</strong>)</li>
</ul>
</section>
<section id="features" class="slide level2">
<h2>Features</h2>
<p>A <strong>feature</strong> is a number obtained by applying simple computations to an image. Very useful information can be obtained directly from features.</p>
<p><strong>Feature extraction</strong>: simple, direct computations applied to sensor responses.</p>
<p><img data-src="img/feature1.jpg"></p>
<p><img data-src="img/feature2.png" class="absolute" style="top: 350px; left: 600px; "></p>
</section>
<section id="model-based-approach" class="slide level2">
<h2>Model-based approach</h2>
<p>Two kinds of models:</p>
<ul>
<li><strong>object model</strong>: precise and geometric</li>
<li><strong>rendering model</strong>: describes the physical, geometric, and statistical processes that produce the stimulus</li>
</ul>
</section>
<section id="core-problems" class="slide level2">
<h2>Core problems</h2>
<p>The two core problems of computer vision are</p>
<ul>
<li><em>reconstruction</em></li>
<li><em>recognition</em></li>
</ul>
</section>
<section id="reconstruction" class="slide level2">
<h2>Reconstruction</h2>
<p>An agent builds a model of the world from an image(s) <!-- https://viso.ai/computer-vision/3d-computer-vision/ --> <img data-src="img/3d_reconstruction.jpg" height="500"></p>
</section>
<section id="recognition" class="slide level2">
<h2>Recognition</h2>
<p>Agent draws distinctions among the objects it encounters based on visual and other information <!-- https://viso.ai/computer-vision/image-recognition/ --> <img data-src="img/image_recognition.jpg" height="500"></p>
</section>
<section id="goals" class="slide level2">
<h2>Goals</h2>
<p>The <strong>goal</strong> of vision is to extract information needed for tasks such as:</p>
<ul>
<li>manipulation</li>
<li>navigation</li>
<li>object recognition</li>
</ul>
</section>
<section id="computer-vision-vs-graphics" class="slide level2">
<h2>Computer Vision vs Graphics</h2>
<div class="columns">
<div class="column fragment" style="width:50%;">
<h3 id="vision">Vision</h3>
<p>Emphasis on <strong>analyzing</strong> images <img data-src="img/tesla_autopilot.png"></p>
</div><div class="column fragment" style="width:50%;">
<h3 id="graphics">Graphics</h3>
<p>Emphasis on <strong>creating</strong> images <img data-src="img/vertigo.png"></p>
</div></div>
</section>
<section id="challenge" class="slide level2">
<h2>Challenge</h2>
<p>Geometry distortion</p>

<img data-src="img/geometry_distortion.png" class="r-stretch"></section>
<section id="challenge-1" class="slide level2">
<h2>Challenge</h2>
<p>Illumination effects</p>

<img data-src="img/illumination_effects.png" class="r-stretch"></section>
<section id="challenge-2" class="slide level2">
<h2>Challenge</h2>
<p>Appearance variation <img data-src="img/image_classification.png"></p>
</section>
<section id="aside-on-cameras" class="slide level2">
<h2>Aside on cameras</h2>
<h3 id="pinhole-camera">Pinhole camera</h3>

<img data-src="img/pinhole_camera.png" class="r-stretch"></section>
<section id="aside-on-cameras-1" class="slide level2">
<h2>Aside on cameras</h2>
<h3 id="lens-camera">Lens camera</h3>

<img data-src="img/lens_camera.png" class="r-stretch"></section>
<section id="aside-on-cameras-2" class="slide level2">
<h2>Aside on cameras</h2>
<h3 id="phone-camera">Phone camera</h3>

<img data-src="img/phone_camera.png" class="r-stretch"></section>
<section id="image-properties" class="slide level2">
<h2>Image properties</h2>
<p>Four general properties of images and video</p>
<ul>
<li>edges</li>
<li>texture</li>
<li>optical flow</li>
<li>segmentation into regions</li>
</ul>
</section>
<section id="edges" class="slide level2">
<h2>Edges</h2>

<img data-src="img/edge_types.png" class="r-stretch"><ol type="1">
<li>depth discontinuities</li>
<li>surface orientation discontinuities</li>
<li>reflectance discontinuities</li>
<li>illumination discontinuities (shadows)</li>
</ol>
</section>
<section id="texture" class="slide level2">
<h2>Texture</h2>

<img data-src="img/textures.jpg" class="r-stretch"></section>
<section id="optical-flow" class="slide level2">
<h2>Optical flow</h2>
<!-- https://viso.ai/deep-learning/optical-flow/ -->

<img data-src="img/optical_flow.jpg" class="r-stretch"></section>
<section id="segmentation" class="slide level2">
<h2>Segmentation</h2>

<img data-src="img/image_segmentation.png" class="r-stretch"></section>
<section id="applications" class="slide level2">
<h2>Applications</h2>
<div class="absolute" style="top: 120px; ">
<ul>
<li>understanding human actions</li>
<li>captioning</li>
<li>geometry reconstruction</li>
<li>image transformation</li>
<li>movement control</li>
</ul>
</div>
<p><img data-src="img/applications1.png" class="absolute" style="top: 50px; left: 600px; height: 200px; "> <img data-src="img/applications3.png" class="absolute" style="top: 200px; left: 500px; height: 300px; "> <img data-src="img/applications4.png" class="absolute" style="top: 450px; left: 650px; height: 200px; "></p>
</section>
<section id="augmented-reality" class="slide level2">
<h2>Augmented Reality</h2>

<img data-src="img/apple_vision_example.png" class="r-stretch"></section>
<section id="augmented-reality-1" class="slide level2">
<h2>Augmented Reality</h2>

<img data-src="img/ar_dystopia.png" class="r-stretch"></section>
<section id="augmented-reality-2" class="slide level2">
<h2>Augmented Reality</h2>

<img data-src="img/street_ar.jpg" class="r-stretch"></section>
<section id="autonomous-driving" class="slide level2">
<h2>Autonomous driving</h2>
<!-- https://opencv.org/blog/opencv-applications-in-2023/#Real-world-OpenCV-Applications -->
<ul>
<li>object detection and lane recognition</li>
<li>adaptive cruise control</li>
<li>real-time environmental perception and decision-making</li>
</ul>
<p><img data-src="img/autonomous_driving.png" height="360"></p>
</section></section>
<section>
<section id="modern-tools" class="title-slide slide level1 center">
<h1>Modern tools</h1>

</section>
<section id="opencv" class="slide level2">
<h2>OpenCV</h2>
<ul>
<li><p><strong>when?:</strong> at Intel in 1999.</p></li>
<li><p><strong>goal:</strong> democratize computer vision</p></li>
</ul>
<!-- 2007: included in the Google Summer of Code program -->
<p><img data-src="img/opencv.png" class="absolute" style="left: 300px; height: 400px; "></p>
</section>
<section id="architecture" class="slide level2">
<h2>Architecture</h2>

<img data-src="img/opencv_arch.jpg" class="r-stretch"></section>
<section id="opencv-modules" class="slide level2 scrollable">
<h2>OpenCV modules</h2>
<!-- https://delftswa.gitbooks.io/desosa2016/content/opencv/Chapter.html#source-code-structure -->
<p><img data-src="img/opencv_modules.png" height="1000"></p>
</section>
<section id="features-1" class="slide level2">
<h2>Features</h2>
<p>The library has more than <strong>2500</strong> optimized algorithms for:</p>
<ul>
<li>face recognition</li>
<li>object identification</li>
<li>human action classification</li>
<li>object tracking</li>
<li>3D model extraction</li>
<li>augmented reality</li>
</ul>
</section>
<section id="where-is-opencv-5" class="slide level2">
<h2>Where is OpenCV 5?</h2>
<blockquote>
<p>Will the future be open? Or will our algorithms be lost in time, like tears in rain?</p>
</blockquote>

<img data-src="img/tears_in_rain.jpg" class="r-stretch"><p><a href="./https://opencv.org/blog/where-is-opencv-5/">https://opencv.org/blog/where-is-opencv-5</a></p>
</section>
<section id="yolo" class="slide level2">
<h2>YOLO</h2>
<p>A single convolutional network simultaneously predicts multiple bounding boxes and class probabilities for those boxes <img data-src="img/yolo_detection_system.png"></p>
<!-- https://arxiv.org/pdf/1506.02640 -->

<aside><div>
<p>You Only Look Once: Unified, Real-Time Object Detection (https://arxiv.org/pdf/1506.02640)</p>
</div></aside></section>
<section id="yolo-model" class="slide level2">
<h2>YOLO model</h2>
<p>Detection as a regression problem</p>

<img data-src="img/yolo_model.png" class="r-stretch"></section>
<section id="yolo-architecture" class="slide level2">
<h2>YOLO architecture</h2>

<img data-src="img/yolo_arch.png" class="r-stretch"></section>
<section id="detrs" class="slide level2">
<h2>DETRs</h2>
<p>End-to-end Transformer-based detectors (DETRs)</p>
<p><img data-src="img/detrs.png"></p>

<aside><div>
<p>End-to-End Object Detection with Transformers (https://arxiv.org/pdf/2005.12872)</p>
</div></aside></section>
<section id="rt-detr" class="slide level2">
<h2>RT-DETR</h2>
<p><img data-src="img/rt_detr.png"> <!-- https://arxiv.org/pdf/2304.08069 --></p>
</section>
<section id="segment-anything" class="slide level2">
<h2>Segment Anything</h2>
<p>Foundation model for image segmentation <!-- https://arxiv.org/pdf/2304.02643 --> <img data-src="img/segment_anything.png"></p>

<aside><div>
<p>Segment Anything (https://arxiv.org/pdf/2304.02643)</p>
</div></aside></section>
<section id="segment-anything-1" class="slide level2">
<h2>Segment Anything</h2>

<img data-src="img/sa_dataset.png" class="r-stretch"></section>
<section id="natural-language-supervision" class="slide level2">
<h2>Natural Language Supervision</h2>
<p><img data-src="img/clip.png"></p>

<aside><div>
<p>Learning Transferable Visual Models From Natural Language Supervision (https://arxiv.org/pdf/2103.00020)</p>
</div></aside></section></section>
<section>
<section id="examples" class="title-slide slide level1 center">
<h1>Examples</h1>

</section>
<section id="basic-image-operations" class="slide level2 scrollable">
<h2>Basic image operations</h2>
<h3 id="reading">Reading</h3>
<div class="panel-tabset">
<ul id="tabset-1" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-1-1">Python code</a></li><li><a href="#tabset-1-2">Example</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1">
<div id="9754186a" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a>retval <span class="op">=</span> cv2.imread( filename[, flags] )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-1-2">
<div id="cell-fig-reading" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2" data-code-line-numbers="5,"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a><span class="im">import</span> cv2</span>
<span id="cb2-2"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-3"><a></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-4"><a></a></span>
<span id="cb2-5"><a></a>img<span class="op">=</span>cv2.imread(<span class="st">"img/yolo_detection_system.png"</span>, cv2.IMREAD_GRAYSCALE)</span>
<span id="cb2-6"><a></a></span>
<span id="cb2-7"><a></a><span class="co">#Displaying image using plt.imshow() method</span></span>
<span id="cb2-8"><a></a>plt.imshow(img)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-reading" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-reading-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="lec1_files/figure-revealjs/fig-reading-output-1.png" width="798" height="208">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-reading-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Image reading example
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<h3 id="writing">Writing</h3>
<div class="panel-tabset">
<ul id="tabset-2" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-2-1">Python code</a></li><li><a href="#tabset-2-2">Example</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1">
<div id="c9c81bd2" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a></a>cv2.imwrite( filename, img[, params] )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-2-2">
<div id="bee32f7e" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a>cv2.imwrite(<span class="st">"new_file.jpg"</span>, img)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>True</code></pre>
</div>
</div>
</div>
</div>
</div>
<h3 id="dimensions">Dimensions</h3>
<div class="r-stack center">
<div id="706f6e11" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a></a><span class="bu">print</span>(<span class="st">"Image size (H, W, C) is:"</span>, img.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Image size (H, W, C) is: (466, 2140)</code></pre>
</div>
</div>
</div>
</section>
<section id="image-cropping" class="slide level2">
<h2>Image cropping</h2>
<div id="8016ed3c" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a></a>cropped <span class="op">=</span> img[<span class="dv">100</span>:<span class="dv">300</span>, <span class="dv">500</span>:<span class="dv">800</span>]</span>
<span id="cb8-2"><a></a>plt.imshow(cropped)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-7-output-1.png" width="608" height="415"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="image-resizing-rotation" class="slide level2 scrollable">
<h2>Image resizing / rotation</h2>
<h3 id="resizing">Resizing</h3>
<div class="panel-tabset">
<ul id="tabset-3" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-3-1">Python code</a></li><li><a href="#tabset-3-2">Example</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1">
<div id="fdabc496" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a></a>dst <span class="op">=</span> resize( src, dsize[, dst[, fx[, fy[, interpolation]]]] )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-3-2">
<div id="bc9bcd15" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a></a>resized <span class="op">=</span> cv2.resize(img, <span class="va">None</span>, fx<span class="op">=</span><span class="fl">0.1</span>, fy<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb10-2"><a></a>plt.imshow(resized)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-9-output-1.png" width="789" height="208"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<h3 id="rotation">Rotation</h3>
<div class="panel-tabset">
<ul id="tabset-4" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-4-1">Python code</a></li><li><a href="#tabset-4-2">Example</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1">
<div id="b4eb5f3a" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a></a>dst <span class="op">=</span> cv.flip( src, flipCode )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-4-2">
<div id="c6d1aa3f" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a></a>rotated <span class="op">=</span> cv2.flip(img, <span class="dv">0</span>)</span>
<span id="cb12-2"><a></a>plt.imshow(rotated)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-11-output-1.png" width="798" height="208"></p>
</figure>
</div>
</div>
</div>
<div id="ea33416d" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a></a>rotated <span class="op">=</span> cv2.flip(img, <span class="dv">1</span>)</span>
<span id="cb13-2"><a></a>plt.imshow(rotated)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-12-output-1.png" width="798" height="208"></p>
</figure>
</div>
</div>
</div>
<div id="9b7f7b01" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a></a>rotated <span class="op">=</span> cv2.flip(img, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb14-2"><a></a>plt.imshow(rotated)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-13-output-1.png" width="798" height="208"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="image-annotation" class="slide level2 scrollable">
<h2>Image annotation</h2>
<div class="panel-tabset">
<ul id="tabset-5" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-5-1">Python code</a></li><li><a href="#tabset-5-2">Example</a></li></ul>
<div class="tab-content">
<div id="tabset-5-1">
<div id="6900ef69" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a></a>img <span class="op">=</span> cv2.line(img, pt1, pt2, color[, thickness[, lineType[, shift]]])</span>
<span id="cb15-2"><a></a>img <span class="op">=</span> cv2.circle(img, center, radius, color[, thickness[, lineType[, shift]]])</span>
<span id="cb15-3"><a></a>img <span class="op">=</span> cv2.rectangle(img, pt1, pt2, color[, thickness[, lineType[, shift]]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-5-2">
<div id="a9e66ff4" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a></a>annotated <span class="op">=</span> cv2.line(img, (<span class="dv">200</span>, <span class="dv">100</span>), (<span class="dv">800</span>, <span class="dv">100</span>), (<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">255</span>), thickness<span class="op">=</span><span class="dv">50</span>, lineType<span class="op">=</span>cv2.LINE_AA)<span class="op">;</span></span>
<span id="cb16-2"><a></a></span>
<span id="cb16-3"><a></a>plt.imshow(annotated)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-15-output-1.png" width="798" height="208"></p>
</figure>
</div>
</div>
</div>
<div id="1894f866" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a></a>annotated2 <span class="op">=</span> cv2.circle(annotated, (<span class="dv">200</span>,<span class="dv">200</span>), <span class="dv">100</span>, (<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">255</span>), thickness<span class="op">=</span><span class="dv">20</span>, lineType<span class="op">=</span>cv2.LINE_AA)<span class="op">;</span></span>
<span id="cb17-2"><a></a>plt.imshow(annotated2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-16-output-1.png" width="798" height="208"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="adding-text" class="slide level2 scrollable">
<h2>Adding text</h2>
<div class="panel-tabset">
<ul id="tabset-6" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-6-1">Python code</a></li><li><a href="#tabset-6-2">Example</a></li></ul>
<div class="tab-content">
<div id="tabset-6-1">
<div id="de03ad5a" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a></a>img <span class="op">=</span> cv2.putText(img, text, org, fontFace, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-6-2">
<div id="8bcf7354" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb19" data-code-line-numbers="8,"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a></a>imageText <span class="op">=</span> img.copy()</span>
<span id="cb19-2"><a></a>text <span class="op">=</span> <span class="st">"Random text"</span></span>
<span id="cb19-3"><a></a>fontScale <span class="op">=</span> <span class="fl">5.3</span></span>
<span id="cb19-4"><a></a>fontFace <span class="op">=</span> cv2.FONT_HERSHEY_PLAIN</span>
<span id="cb19-5"><a></a>fontColor <span class="op">=</span> (<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>)</span>
<span id="cb19-6"><a></a>fontThickness <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb19-7"><a></a></span>
<span id="cb19-8"><a></a>cv2.putText(imageText, text, (<span class="dv">100</span>, <span class="dv">300</span>), fontFace, fontScale, fontColor, fontThickness, cv2.LINE_AA)<span class="op">;</span></span>
<span id="cb19-9"><a></a></span>
<span id="cb19-10"><a></a><span class="co"># Display the image</span></span>
<span id="cb19-11"><a></a>plt.imshow(imageText)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-18-output-1.png" width="798" height="208"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="image-thresholding" class="slide level2">
<h2>Image Thresholding</h2>
<div class="panel-tabset">
<ul id="tabset-7" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-7-1">Python code</a></li><li><a href="#tabset-7-2">Example</a></li></ul>
<div class="tab-content">
<div id="tabset-7-1">
<div id="13e56b87" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a></a>retval, dst <span class="op">=</span> cv2.threshold( src, thresh, maxval, <span class="bu">type</span>[, dst] )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-7-2">
<div id="96aeb991" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb21" data-code-line-numbers="1,"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a></a>retval, img_thresh <span class="op">=</span> cv2.threshold(img, <span class="dv">100</span>, <span class="dv">255</span>, cv2.THRESH_BINARY)</span>
<span id="cb21-2"><a></a></span>
<span id="cb21-3"><a></a><span class="co"># Show the images</span></span>
<span id="cb21-4"><a></a>plt.figure(figsize<span class="op">=</span>[<span class="dv">18</span>, <span class="dv">5</span>])</span>
<span id="cb21-5"><a></a></span>
<span id="cb21-6"><a></a>plt.subplot(<span class="dv">121</span>)<span class="op">;</span>plt.imshow(img, cmap<span class="op">=</span><span class="st">"gray"</span>)<span class="op">;</span>  plt.title(<span class="st">"Original"</span>)</span>
<span id="cb21-7"><a></a>plt.subplot(<span class="dv">122</span>)<span class="op">;</span>plt.imshow(img_thresh, cmap<span class="op">=</span><span class="st">"gray"</span>)<span class="op">;</span>plt.title(<span class="st">"Thresholded"</span>)</span>
<span id="cb21-8"><a></a></span>
<span id="cb21-9"><a></a><span class="bu">print</span>(img_thresh.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(466, 2140)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-20-output-2.png" width="1393" height="194"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="haar-cascade-classifiers" class="slide level2">
<h2>Haar cascade classifiers</h2>
<p>A Haar feature is essentially calculations that are performed on adjacent rectangular regions at a specific location in a detection window. <img data-src="img/cascade_classifier.png"></p>
</section>
<section id="code-example" class="slide level2 scrollable">
<h2>Code example</h2>
<div class="panel-tabset">
<ul id="tabset-8" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-8-1">Preparation</a></li><li><a href="#tabset-8-2">Execution</a></li></ul>
<div class="tab-content">
<div id="tabset-8-1">
<div id="e68c9fce" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a></a><span class="co"># Load the Haar Cascade Classifier</span></span>
<span id="cb23-2"><a></a>face_cascade <span class="op">=</span> cv2.CascadeClassifier(<span class="st">'haarcascade_frontalface_default.xml'</span>)</span>
<span id="cb23-3"><a></a></span>
<span id="cb23-4"><a></a><span class="co"># Read the image</span></span>
<span id="cb23-5"><a></a>img <span class="op">=</span> cv2.imread(<span class="st">'diverse_faces.jpg'</span>)</span>
<span id="cb23-6"><a></a>plt.imshow(img)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-21-output-1.png" width="412" height="416"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-8-2">
<div id="b0034dcb" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a></a>gray <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span>
<span id="cb24-2"><a></a></span>
<span id="cb24-3"><a></a><span class="co"># Detect faces</span></span>
<span id="cb24-4"><a></a>faces <span class="op">=</span> face_cascade.detectMultiScale(gray, scaleFactor<span class="op">=</span><span class="fl">1.1</span>, minNeighbors<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb24-5"><a></a></span>
<span id="cb24-6"><a></a><span class="co"># Draw rectangles around faces</span></span>
<span id="cb24-7"><a></a><span class="cf">for</span> (x, y, w, h) <span class="kw">in</span> faces:</span>
<span id="cb24-8"><a></a>    cv2.rectangle(img, (x, y), (x<span class="op">+</span>w, y<span class="op">+</span>h), (<span class="dv">255</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="dv">2</span>)</span>
<span id="cb24-9"><a></a>plt.imshow(img)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-22-output-1.png" width="412" height="416"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="pose-estimation" class="slide level2 scrollable">
<h2>Pose estimation</h2>
<!-- https://arxiv.org/pdf/1812.08008 -->

<img data-src="img/pose_estimation.png" class="r-stretch"></section>
<section id="pose-estimation-1" class="slide level2 scrollable">
<h2>Pose estimation</h2>
<div id="9d4f7e4a" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a></a><span class="im">import</span> os</span>
<span id="cb25-2"><a></a><span class="im">from</span> IPython.display <span class="im">import</span> YouTubeVideo, display, Image</span>
<span id="cb25-3"><a></a></span>
<span id="cb25-4"><a></a>protoFile   <span class="op">=</span> <span class="st">"pose_deploy_linevec_faster_4_stages.prototxt"</span></span>
<span id="cb25-5"><a></a>weightsFile <span class="op">=</span> os.path.join(<span class="st">"model"</span>, <span class="st">"pose_iter_160000.caffemodel"</span>)</span>
<span id="cb25-6"><a></a>net <span class="op">=</span> cv2.dnn.readNetFromCaffe(protoFile, weightsFile)</span>
<span id="cb25-7"><a></a>im <span class="op">=</span> cv2.imread(<span class="st">"jump.png"</span>) <span class="co">#"Tiger_Woods_crop.png")</span></span>
<span id="cb25-8"><a></a>im <span class="op">=</span> cv2.cvtColor(im, cv2.COLOR_BGR2RGB)</span>
<span id="cb25-9"><a></a></span>
<span id="cb25-10"><a></a>inWidth  <span class="op">=</span> im.shape[<span class="dv">1</span>]</span>
<span id="cb25-11"><a></a>inHeight <span class="op">=</span> im.shape[<span class="dv">0</span>]</span>
<span id="cb25-12"><a></a></span>
<span id="cb25-13"><a></a>nPoints <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb25-14"><a></a>POSE_PAIRS <span class="op">=</span> [</span>
<span id="cb25-15"><a></a>    [<span class="dv">0</span>, <span class="dv">1</span>],</span>
<span id="cb25-16"><a></a>    [<span class="dv">1</span>, <span class="dv">2</span>],</span>
<span id="cb25-17"><a></a>    [<span class="dv">2</span>, <span class="dv">3</span>],</span>
<span id="cb25-18"><a></a>    [<span class="dv">3</span>, <span class="dv">4</span>],</span>
<span id="cb25-19"><a></a>    [<span class="dv">1</span>, <span class="dv">5</span>],</span>
<span id="cb25-20"><a></a>    [<span class="dv">5</span>, <span class="dv">6</span>],</span>
<span id="cb25-21"><a></a>    [<span class="dv">6</span>, <span class="dv">7</span>],</span>
<span id="cb25-22"><a></a>    [<span class="dv">1</span>, <span class="dv">14</span>],</span>
<span id="cb25-23"><a></a>    [<span class="dv">14</span>, <span class="dv">8</span>],</span>
<span id="cb25-24"><a></a>    [<span class="dv">8</span>, <span class="dv">9</span>],</span>
<span id="cb25-25"><a></a>    [<span class="dv">9</span>, <span class="dv">10</span>],</span>
<span id="cb25-26"><a></a>    [<span class="dv">14</span>, <span class="dv">11</span>],</span>
<span id="cb25-27"><a></a>    [<span class="dv">11</span>, <span class="dv">12</span>],</span>
<span id="cb25-28"><a></a>    [<span class="dv">12</span>, <span class="dv">13</span>],</span>
<span id="cb25-29"><a></a>]</span>
<span id="cb25-30"><a></a></span>
<span id="cb25-31"><a></a>netInputSize <span class="op">=</span> (<span class="dv">368</span>, <span class="dv">368</span>)</span>
<span id="cb25-32"><a></a>inpBlob <span class="op">=</span> cv2.dnn.blobFromImage(im, <span class="fl">1.0</span> <span class="op">/</span> <span class="dv">255</span>, netInputSize, (<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), swapRB<span class="op">=</span><span class="va">True</span>, crop<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb25-33"><a></a>net.setInput(inpBlob)</span>
<span id="cb25-34"><a></a></span>
<span id="cb25-35"><a></a><span class="co"># Forward Pass</span></span>
<span id="cb25-36"><a></a>output <span class="op">=</span> net.forward()</span>
<span id="cb25-37"><a></a></span>
<span id="cb25-38"><a></a><span class="co"># Display probability maps</span></span>
<span id="cb25-39"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">5</span>))</span>
<span id="cb25-40"><a></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(nPoints):</span>
<span id="cb25-41"><a></a>    probMap <span class="op">=</span> output[<span class="dv">0</span>, i, :, :]</span>
<span id="cb25-42"><a></a>    displayMap <span class="op">=</span> cv2.resize(probMap, (inWidth, inHeight), cv2.INTER_LINEAR)</span>
<span id="cb25-43"><a></a></span>
<span id="cb25-44"><a></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">8</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb25-45"><a></a>    plt.axis(<span class="st">"off"</span>)</span>
<span id="cb25-46"><a></a>    plt.imshow(displayMap, cmap<span class="op">=</span><span class="st">"jet"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-23-output-1.png" width="1507" height="326"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="pose-estimation-2" class="slide level2 scrollable">
<h2>Pose estimation</h2>
<div id="31b29ec1" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a></a><span class="co"># X and Y Scale</span></span>
<span id="cb26-2"><a></a>scaleX <span class="op">=</span> inWidth  <span class="op">/</span> output.shape[<span class="dv">3</span>]</span>
<span id="cb26-3"><a></a>scaleY <span class="op">=</span> inHeight <span class="op">/</span> output.shape[<span class="dv">2</span>]</span>
<span id="cb26-4"><a></a></span>
<span id="cb26-5"><a></a><span class="co"># Empty list to store the detected keypoints</span></span>
<span id="cb26-6"><a></a>points <span class="op">=</span> []</span>
<span id="cb26-7"><a></a></span>
<span id="cb26-8"><a></a><span class="co"># Treshold</span></span>
<span id="cb26-9"><a></a>threshold <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb26-10"><a></a></span>
<span id="cb26-11"><a></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(nPoints):</span>
<span id="cb26-12"><a></a>    <span class="co"># Obtain probability map</span></span>
<span id="cb26-13"><a></a>    probMap <span class="op">=</span> output[<span class="dv">0</span>, i, :, :]</span>
<span id="cb26-14"><a></a></span>
<span id="cb26-15"><a></a>    <span class="co"># Find global maxima of the probMap.</span></span>
<span id="cb26-16"><a></a>    minVal, prob, minLoc, point <span class="op">=</span> cv2.minMaxLoc(probMap)</span>
<span id="cb26-17"><a></a></span>
<span id="cb26-18"><a></a>    <span class="co"># Scale the point to fit on the original image</span></span>
<span id="cb26-19"><a></a>    x <span class="op">=</span> scaleX <span class="op">*</span> point[<span class="dv">0</span>]</span>
<span id="cb26-20"><a></a>    y <span class="op">=</span> scaleY <span class="op">*</span> point[<span class="dv">1</span>]</span>
<span id="cb26-21"><a></a></span>
<span id="cb26-22"><a></a>    <span class="cf">if</span> prob <span class="op">&gt;</span> threshold:</span>
<span id="cb26-23"><a></a>        <span class="co"># Add the point to the list if the probability is greater than the threshold</span></span>
<span id="cb26-24"><a></a>        points.append((<span class="bu">int</span>(x), <span class="bu">int</span>(y)))</span>
<span id="cb26-25"><a></a>    <span class="cf">else</span>:</span>
<span id="cb26-26"><a></a>        points.append(<span class="va">None</span>)</span>
<span id="cb26-27"><a></a></span>
<span id="cb26-28"><a></a>imPoints <span class="op">=</span> im.copy()</span>
<span id="cb26-29"><a></a>imSkeleton <span class="op">=</span> im.copy()</span>
<span id="cb26-30"><a></a></span>
<span id="cb26-31"><a></a><span class="co"># Draw points</span></span>
<span id="cb26-32"><a></a><span class="cf">for</span> i, p <span class="kw">in</span> <span class="bu">enumerate</span>(points):</span>
<span id="cb26-33"><a></a>    cv2.circle(imPoints, p, <span class="dv">8</span>, (<span class="dv">255</span>, <span class="dv">255</span>, <span class="dv">0</span>), thickness<span class="op">=-</span><span class="dv">1</span>, lineType<span class="op">=</span>cv2.FILLED)</span>
<span id="cb26-34"><a></a>    cv2.putText(imPoints, <span class="st">"</span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(i), p, cv2.FONT_HERSHEY_SIMPLEX, <span class="dv">1</span>, (<span class="dv">255</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="dv">2</span>, lineType<span class="op">=</span>cv2.LINE_AA)</span>
<span id="cb26-35"><a></a></span>
<span id="cb26-36"><a></a><span class="co"># Draw skeleton</span></span>
<span id="cb26-37"><a></a><span class="cf">for</span> pair <span class="kw">in</span> POSE_PAIRS:</span>
<span id="cb26-38"><a></a>    partA <span class="op">=</span> pair[<span class="dv">0</span>]</span>
<span id="cb26-39"><a></a>    partB <span class="op">=</span> pair[<span class="dv">1</span>]</span>
<span id="cb26-40"><a></a></span>
<span id="cb26-41"><a></a>    <span class="cf">if</span> points[partA] <span class="kw">and</span> points[partB]:</span>
<span id="cb26-42"><a></a>        cv2.line(imSkeleton, points[partA], points[partB], (<span class="dv">255</span>, <span class="dv">255</span>, <span class="dv">0</span>), <span class="dv">2</span>)</span>
<span id="cb26-43"><a></a>        cv2.circle(imSkeleton, points[partA], <span class="dv">8</span>, (<span class="dv">255</span>, <span class="dv">0</span>, <span class="dv">0</span>), thickness<span class="op">=-</span><span class="dv">1</span>, lineType<span class="op">=</span>cv2.FILLED)</span>
<span id="cb26-44"><a></a></span>
<span id="cb26-45"><a></a>plt.figure() <span class="co">#figsize=(50, 50))</span></span>
<span id="cb26-46"><a></a></span>
<span id="cb26-47"><a></a>plt.subplot(<span class="dv">121</span>)</span>
<span id="cb26-48"><a></a>plt.axis(<span class="st">"off"</span>)</span>
<span id="cb26-49"><a></a>plt.imshow(imPoints)</span>
<span id="cb26-50"><a></a></span>
<span id="cb26-51"><a></a>plt.subplot(<span class="dv">122</span>)</span>
<span id="cb26-52"><a></a>plt.axis(<span class="st">"off"</span>)</span>
<span id="cb26-53"><a></a>plt.imshow(imSkeleton)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-24-output-1.png" width="763" height="245"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="east" class="slide level2">
<h2>EAST</h2>
<!-- https://github.com/ZER-0-NE/EAST-Detector-for-text-detection-using-OpenCV/blob/master/opencv_text_detection_image.py -->
<!-- https://pyimagesearch.com/2018/08/20/opencv-text-detection-east-text-detector/ -->
<!-- EAST paper: https://arxiv.org/pdf/1704.03155 -->
<h3 id="east-an-efficient-and-accurate-scene-text-detector">EAST: An Efficient and Accurate Scene Text Detector</h3>

<img data-src="img/east.png" class="r-stretch"></section>
<section id="east-1" class="slide level2">
<h2>EAST</h2>
<div class="r-stack center">
<p><img data-src="img/chocolate.png"></p>
</div>
</section>
<section id="east-2" class="slide level2">
<h2>EAST</h2>
<div id="433ff2da" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a></a><span class="co"># load the input image and grab the image dimensions</span></span>
<span id="cb27-2"><a></a>image <span class="op">=</span> cv2.imread(<span class="st">"img/chocolate.png"</span>)</span>
<span id="cb27-3"><a></a>orig <span class="op">=</span> image.copy()</span>
<span id="cb27-4"><a></a>(H, W) <span class="op">=</span> image.shape[:<span class="dv">2</span>]</span>
<span id="cb27-5"><a></a></span>
<span id="cb27-6"><a></a>width <span class="op">=</span> <span class="dv">320</span></span>
<span id="cb27-7"><a></a>height <span class="op">=</span> <span class="dv">320</span></span>
<span id="cb27-8"><a></a><span class="co"># set the new width and height and then determine the ratio in change</span></span>
<span id="cb27-9"><a></a><span class="co"># for both the width and height</span></span>
<span id="cb27-10"><a></a>(newW, newH) <span class="op">=</span> (width, height)</span>
<span id="cb27-11"><a></a>rW <span class="op">=</span> W <span class="op">/</span> <span class="bu">float</span>(newW)</span>
<span id="cb27-12"><a></a>rH <span class="op">=</span> H <span class="op">/</span> <span class="bu">float</span>(newH)</span>
<span id="cb27-13"><a></a></span>
<span id="cb27-14"><a></a><span class="co"># resize the image and grab the new image dimensions</span></span>
<span id="cb27-15"><a></a>image <span class="op">=</span> cv2.resize(image, (newW, newH))</span>
<span id="cb27-16"><a></a>(H, W) <span class="op">=</span> image.shape[:<span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="east-3" class="slide level2">
<h2>EAST</h2>
<div id="1958dbb2" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a></a><span class="co"># define the two output layer names for the EAST detector model that</span></span>
<span id="cb28-2"><a></a><span class="co"># we are interested -- the first is the output probabilities and the</span></span>
<span id="cb28-3"><a></a><span class="co"># second can be used to derive the bounding box coordinates of text</span></span>
<span id="cb28-4"><a></a>layerNames <span class="op">=</span> [</span>
<span id="cb28-5"><a></a>    <span class="st">"feature_fusion/Conv_7/Sigmoid"</span>,</span>
<span id="cb28-6"><a></a>    <span class="st">"feature_fusion/concat_3"</span>]</span>
<span id="cb28-7"><a></a></span>
<span id="cb28-8"><a></a><span class="co"># load the pre-trained EAST text detector</span></span>
<span id="cb28-9"><a></a><span class="bu">print</span>(<span class="st">"[INFO] loading EAST text detector..."</span>)</span>
<span id="cb28-10"><a></a>net <span class="op">=</span> cv2.dnn.readNet(<span class="st">"frozen_east_text_detection.pb"</span>)</span>
<span id="cb28-11"><a></a></span>
<span id="cb28-12"><a></a><span class="co"># construct a blob from the image and then perform a forward pass of</span></span>
<span id="cb28-13"><a></a><span class="co"># the model to obtain the two output layer sets</span></span>
<span id="cb28-14"><a></a>blob <span class="op">=</span> cv2.dnn.blobFromImage(image, <span class="fl">1.0</span>, (W, H),</span>
<span id="cb28-15"><a></a>                             (<span class="fl">123.68</span>, <span class="fl">116.78</span>, <span class="fl">103.94</span>), swapRB<span class="op">=</span><span class="va">True</span>, crop<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] loading EAST text detector...</code></pre>
</div>
</div>
</section>
<section id="east-4" class="slide level2">
<h2>EAST</h2>
<div id="b8da6e8f" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a></a><span class="im">import</span> time</span>
<span id="cb30-2"><a></a><span class="im">from</span> imutils.object_detection <span class="im">import</span> non_max_suppression</span>
<span id="cb30-3"><a></a></span>
<span id="cb30-4"><a></a></span>
<span id="cb30-5"><a></a>confidence <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb30-6"><a></a></span>
<span id="cb30-7"><a></a>start <span class="op">=</span> time.time()</span>
<span id="cb30-8"><a></a>net.setInput(blob)</span>
<span id="cb30-9"><a></a>(scores, geometry) <span class="op">=</span> net.forward(layerNames)</span>
<span id="cb30-10"><a></a>end <span class="op">=</span> time.time()</span>
<span id="cb30-11"><a></a></span>
<span id="cb30-12"><a></a><span class="co"># show timing information on text prediction</span></span>
<span id="cb30-13"><a></a><span class="bu">print</span>(<span class="st">"[INFO] text detection took </span><span class="sc">{:.6f}</span><span class="st"> seconds"</span>.<span class="bu">format</span>(end <span class="op">-</span> start))</span>
<span id="cb30-14"><a></a></span>
<span id="cb30-15"><a></a><span class="co"># grab the number of rows and columns from the scores volume, then</span></span>
<span id="cb30-16"><a></a><span class="co"># initialize our set of bounding box rectangles and corresponding</span></span>
<span id="cb30-17"><a></a><span class="co"># confidence scores</span></span>
<span id="cb30-18"><a></a>(numRows, numCols) <span class="op">=</span> scores.shape[<span class="dv">2</span>:<span class="dv">4</span>]</span>
<span id="cb30-19"><a></a>rects <span class="op">=</span> []</span>
<span id="cb30-20"><a></a>confidences <span class="op">=</span> []</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] text detection took 0.099429 seconds</code></pre>
</div>
</div>
</section>
<section id="east-5" class="slide level2">
<h2>EAST</h2>
<div id="5f3323b5" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a></a><span class="co"># loop over the number of rows</span></span>
<span id="cb32-2"><a></a><span class="cf">for</span> y <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, numRows):</span>
<span id="cb32-3"><a></a>    <span class="co"># extract the scores (probabilities), followed by the geometrical</span></span>
<span id="cb32-4"><a></a>    <span class="co"># data used to derive potential bounding box coordinates that</span></span>
<span id="cb32-5"><a></a>    <span class="co"># surround text</span></span>
<span id="cb32-6"><a></a>    scoresData <span class="op">=</span> scores[<span class="dv">0</span>, <span class="dv">0</span>, y]</span>
<span id="cb32-7"><a></a>    xData0 <span class="op">=</span> geometry[<span class="dv">0</span>, <span class="dv">0</span>, y]</span>
<span id="cb32-8"><a></a>    xData1 <span class="op">=</span> geometry[<span class="dv">0</span>, <span class="dv">1</span>, y]</span>
<span id="cb32-9"><a></a>    xData2 <span class="op">=</span> geometry[<span class="dv">0</span>, <span class="dv">2</span>, y]</span>
<span id="cb32-10"><a></a>    xData3 <span class="op">=</span> geometry[<span class="dv">0</span>, <span class="dv">3</span>, y]</span>
<span id="cb32-11"><a></a>    anglesData <span class="op">=</span> geometry[<span class="dv">0</span>, <span class="dv">4</span>, y]</span>
<span id="cb32-12"><a></a></span>
<span id="cb32-13"><a></a>    <span class="co"># loop over the number of columns</span></span>
<span id="cb32-14"><a></a>    <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, numCols):</span>
<span id="cb32-15"><a></a>        <span class="co"># if our score does not have sufficient probability, ignore it</span></span>
<span id="cb32-16"><a></a>        <span class="cf">if</span> scoresData[x] <span class="op">&lt;</span> confidence:</span>
<span id="cb32-17"><a></a>            <span class="cf">continue</span></span>
<span id="cb32-18"><a></a></span>
<span id="cb32-19"><a></a>        <span class="co"># compute the offset factor as our resulting feature maps will</span></span>
<span id="cb32-20"><a></a>        <span class="co"># be 4x smaller than the input image</span></span>
<span id="cb32-21"><a></a>        (offsetX, offsetY) <span class="op">=</span> (x <span class="op">*</span> <span class="fl">4.0</span>, y <span class="op">*</span> <span class="fl">4.0</span>)</span>
<span id="cb32-22"><a></a></span>
<span id="cb32-23"><a></a>        <span class="co"># extract the rotation angle for the prediction and then</span></span>
<span id="cb32-24"><a></a>        <span class="co"># compute the sin and cosine</span></span>
<span id="cb32-25"><a></a>        angle <span class="op">=</span> anglesData[x]</span>
<span id="cb32-26"><a></a>        cos <span class="op">=</span> np.cos(angle)</span>
<span id="cb32-27"><a></a>        sin <span class="op">=</span> np.sin(angle)</span>
<span id="cb32-28"><a></a></span>
<span id="cb32-29"><a></a>        <span class="co"># use the geometry volume to derive the width and height of</span></span>
<span id="cb32-30"><a></a>        <span class="co"># the bounding box</span></span>
<span id="cb32-31"><a></a>        h <span class="op">=</span> xData0[x] <span class="op">+</span> xData2[x]</span>
<span id="cb32-32"><a></a>        w <span class="op">=</span> xData1[x] <span class="op">+</span> xData3[x]</span>
<span id="cb32-33"><a></a></span>
<span id="cb32-34"><a></a>        <span class="co"># compute both the starting and ending (x, y)-coordinates for</span></span>
<span id="cb32-35"><a></a>        <span class="co"># the text prediction bounding box</span></span>
<span id="cb32-36"><a></a>        endX <span class="op">=</span> <span class="bu">int</span>(offsetX <span class="op">+</span> (cos <span class="op">*</span> xData1[x]) <span class="op">+</span> (sin <span class="op">*</span> xData2[x]))</span>
<span id="cb32-37"><a></a>        endY <span class="op">=</span> <span class="bu">int</span>(offsetY <span class="op">-</span> (sin <span class="op">*</span> xData1[x]) <span class="op">+</span> (cos <span class="op">*</span> xData2[x]))</span>
<span id="cb32-38"><a></a>        startX <span class="op">=</span> <span class="bu">int</span>(endX <span class="op">-</span> w)</span>
<span id="cb32-39"><a></a>        startY <span class="op">=</span> <span class="bu">int</span>(endY <span class="op">-</span> h)</span>
<span id="cb32-40"><a></a></span>
<span id="cb32-41"><a></a>        <span class="co"># add the bounding box coordinates and probability score to</span></span>
<span id="cb32-42"><a></a>        <span class="co"># our respective lists</span></span>
<span id="cb32-43"><a></a>        rects.append((startX, startY, endX, endY))</span>
<span id="cb32-44"><a></a>        confidences.append(scoresData[x])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="east-6" class="slide level2 scrollable">
<h2>EAST</h2>
<div class="r-stack center">
<div id="17a6cb09" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a></a><span class="co"># apply non-maxima suppression to suppress weak, overlapping bounding</span></span>
<span id="cb33-2"><a></a><span class="co"># boxes</span></span>
<span id="cb33-3"><a></a>boxes <span class="op">=</span> non_max_suppression(np.array(rects), probs<span class="op">=</span>confidences)</span>
<span id="cb33-4"><a></a></span>
<span id="cb33-5"><a></a><span class="co"># loop over the bounding boxes</span></span>
<span id="cb33-6"><a></a><span class="cf">for</span> (startX, startY, endX, endY) <span class="kw">in</span> boxes:</span>
<span id="cb33-7"><a></a>    <span class="co"># scale the bounding box coordinates based on the respective</span></span>
<span id="cb33-8"><a></a>    <span class="co"># ratios</span></span>
<span id="cb33-9"><a></a>    startX <span class="op">=</span> <span class="bu">int</span>(startX <span class="op">*</span> rW)</span>
<span id="cb33-10"><a></a>    startY <span class="op">=</span> <span class="bu">int</span>(startY <span class="op">*</span> rH)</span>
<span id="cb33-11"><a></a>    endX <span class="op">=</span> <span class="bu">int</span>(endX <span class="op">*</span> rW)</span>
<span id="cb33-12"><a></a>    endY <span class="op">=</span> <span class="bu">int</span>(endY <span class="op">*</span> rH)</span>
<span id="cb33-13"><a></a></span>
<span id="cb33-14"><a></a>    <span class="co"># draw the bounding box on the image</span></span>
<span id="cb33-15"><a></a>    cv2.rectangle(orig, (startX, startY), (endX, endY), (<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>), <span class="dv">2</span>)</span>
<span id="cb33-16"><a></a></span>
<span id="cb33-17"><a></a><span class="co"># show the output image</span></span>
<span id="cb33-18"><a></a>plt.imshow(orig)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-29-output-1.png" width="424" height="416"></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="image-segmentation" class="slide level2 scrollable">
<h2>Image segmentation</h2>
<!-- https://www.geeksforgeeks.org/image-segmentation-with-watershed-algorithm-opencv-python/ -->
<div class="panel-tabset">
<ul id="tabset-9" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-9-1">Preparation</a></li><li><a href="#tabset-9-2">Grayscale</a></li><li><a href="#tabset-9-3">Otsu</a></li><li><a href="#tabset-9-4">Noise removal</a></li></ul>
<div class="tab-content">
<div id="tabset-9-1">
<div id="3ad06831" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a></a><span class="im">import</span> cv2</span>
<span id="cb34-2"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb34-3"><a></a><span class="im">from</span> IPython.display <span class="im">import</span> Image, display</span>
<span id="cb34-4"><a></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb34-5"><a></a></span>
<span id="cb34-6"><a></a><span class="co"># Plot the image</span></span>
<span id="cb34-7"><a></a><span class="kw">def</span> imshow(img, ax<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb34-8"><a></a>    <span class="cf">if</span> ax <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb34-9"><a></a>        plt.imshow(img)</span>
<span id="cb34-10"><a></a>    <span class="cf">else</span>:</span>
<span id="cb34-11"><a></a>        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))</span>
<span id="cb34-12"><a></a>        ax.axis(<span class="st">'off'</span>)</span>
<span id="cb34-13"><a></a></span>
<span id="cb34-14"><a></a><span class="co">#Image loading</span></span>
<span id="cb34-15"><a></a>img <span class="op">=</span> cv2.imread(<span class="st">"img/coins.png"</span>)</span>
<span id="cb34-16"><a></a><span class="co"># Show image</span></span>
<span id="cb34-17"><a></a>imshow(img)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-30-output-1.png" width="365" height="416"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-9-2">
<div id="751999c2" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a></a><span class="co">#image grayscale conversion</span></span>
<span id="cb35-2"><a></a>gray <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span>
<span id="cb35-3"><a></a>imshow(gray)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-31-output-1.png" width="365" height="416"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-9-3">
<div id="fc0f85bb" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a></a><span class="co">#Threshold Processing</span></span>
<span id="cb36-2"><a></a>ret, bin_img <span class="op">=</span> cv2.threshold(gray,</span>
<span id="cb36-3"><a></a>                            <span class="dv">0</span>, <span class="dv">255</span>, </span>
<span id="cb36-4"><a></a>                            cv2.THRESH_BINARY_INV <span class="op">+</span> cv2.THRESH_OTSU)</span>
<span id="cb36-5"><a></a>imshow(bin_img)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-32-output-1.png" width="365" height="416"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-9-4">
<div id="26020dd7" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a></a>kernel <span class="op">=</span> cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="dv">3</span>, <span class="dv">3</span>))</span>
<span id="cb37-2"><a></a>bin_img <span class="op">=</span> cv2.morphologyEx(bin_img, </span>
<span id="cb37-3"><a></a>                        cv2.MORPH_OPEN,</span>
<span id="cb37-4"><a></a>                        kernel,</span>
<span id="cb37-5"><a></a>                        iterations<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb37-6"><a></a>imshow(bin_img)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-33-output-1.png" width="365" height="416"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="image-segmentation-1" class="slide level2 scrollable">
<h2>Image segmentation</h2>
<div class="panel-tabset">
<ul id="tabset-10" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-10-1">Bg/fg/unknown</a></li><li><a href="#tabset-10-2">Markers</a></li><li><a href="#tabset-10-3">Final</a></li></ul>
<div class="tab-content">
<div id="tabset-10-1">
<div id="c7d36c60" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a></a><span class="co"># Create subplots with 1 row and 2 columns</span></span>
<span id="cb38-2"><a></a>fig, axes <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">2</span>, ncols<span class="op">=</span><span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb38-3"><a></a><span class="co"># sure background area</span></span>
<span id="cb38-4"><a></a>sure_bg <span class="op">=</span> cv2.dilate(bin_img, kernel, iterations<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb38-5"><a></a>imshow(sure_bg, axes[<span class="dv">0</span>,<span class="dv">0</span>])</span>
<span id="cb38-6"><a></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="st">'Sure Background'</span>)</span>
<span id="cb38-7"><a></a></span>
<span id="cb38-8"><a></a><span class="co"># Distance transform</span></span>
<span id="cb38-9"><a></a>dist <span class="op">=</span> cv2.distanceTransform(bin_img, cv2.DIST_L2, <span class="dv">5</span>)</span>
<span id="cb38-10"><a></a>imshow(dist, axes[<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb38-11"><a></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_title(<span class="st">'Distance Transform'</span>)</span>
<span id="cb38-12"><a></a></span>
<span id="cb38-13"><a></a><span class="co">#foreground area</span></span>
<span id="cb38-14"><a></a>ret, sure_fg <span class="op">=</span> cv2.threshold(dist, <span class="fl">0.5</span> <span class="op">*</span> dist.<span class="bu">max</span>(), <span class="dv">255</span>, cv2.THRESH_BINARY)</span>
<span id="cb38-15"><a></a>sure_fg <span class="op">=</span> sure_fg.astype(np.uint8) </span>
<span id="cb38-16"><a></a>imshow(sure_fg, axes[<span class="dv">1</span>,<span class="dv">0</span>])</span>
<span id="cb38-17"><a></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_title(<span class="st">'Sure Foreground'</span>)</span>
<span id="cb38-18"><a></a></span>
<span id="cb38-19"><a></a><span class="co"># unknown area</span></span>
<span id="cb38-20"><a></a>unknown <span class="op">=</span> cv2.subtract(sure_bg, sure_fg)</span>
<span id="cb38-21"><a></a>imshow(unknown, axes[<span class="dv">1</span>,<span class="dv">1</span>])</span>
<span id="cb38-22"><a></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_title(<span class="st">'Unknown'</span>)</span>
<span id="cb38-23"><a></a></span>
<span id="cb38-24"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-34-output-1.png" width="564" height="631"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-10-2">
<div id="83a26cf9" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a></a><span class="co"># Marker labelling</span></span>
<span id="cb39-2"><a></a><span class="co"># sure foreground </span></span>
<span id="cb39-3"><a></a>ret, markers <span class="op">=</span> cv2.connectedComponents(sure_fg)</span>
<span id="cb39-4"><a></a></span>
<span id="cb39-5"><a></a><span class="co"># Add one to all labels so that background is not 0, but 1</span></span>
<span id="cb39-6"><a></a>markers <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb39-7"><a></a><span class="co"># mark the region of unknown with zero</span></span>
<span id="cb39-8"><a></a>markers[unknown <span class="op">==</span> <span class="dv">255</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb39-9"><a></a></span>
<span id="cb39-10"><a></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb39-11"><a></a>ax.imshow(markers, cmap<span class="op">=</span><span class="st">"tab20b"</span>)</span>
<span id="cb39-12"><a></a>ax.axis(<span class="st">'off'</span>)</span>
<span id="cb39-13"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-35-output-1.png" width="383" height="463"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-10-3">
<div id="8351bdb0" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a></a><span class="co"># watershed Algorithm</span></span>
<span id="cb40-2"><a></a>markers <span class="op">=</span> cv2.watershed(img, markers)</span>
<span id="cb40-3"><a></a></span>
<span id="cb40-4"><a></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))</span>
<span id="cb40-5"><a></a>ax.imshow(markers, cmap<span class="op">=</span><span class="st">"tab20b"</span>)</span>
<span id="cb40-6"><a></a>ax.axis(<span class="st">'off'</span>)</span>
<span id="cb40-7"><a></a>plt.show()</span>
<span id="cb40-8"><a></a></span>
<span id="cb40-9"><a></a></span>
<span id="cb40-10"><a></a>labels <span class="op">=</span> np.unique(markers)</span>
<span id="cb40-11"><a></a></span>
<span id="cb40-12"><a></a>coins <span class="op">=</span> []</span>
<span id="cb40-13"><a></a><span class="cf">for</span> label <span class="kw">in</span> labels[<span class="dv">2</span>:]: </span>
<span id="cb40-14"><a></a></span>
<span id="cb40-15"><a></a><span class="co"># Create a binary image in which only the area of the label is in the foreground </span></span>
<span id="cb40-16"><a></a><span class="co">#and the rest of the image is in the background </span></span>
<span id="cb40-17"><a></a>    target <span class="op">=</span> np.where(markers <span class="op">==</span> label, <span class="dv">255</span>, <span class="dv">0</span>).astype(np.uint8)</span>
<span id="cb40-18"><a></a></span>
<span id="cb40-19"><a></a><span class="co"># Perform contour extraction on the created binary image</span></span>
<span id="cb40-20"><a></a>    contours, hierarchy <span class="op">=</span> cv2.findContours(</span>
<span id="cb40-21"><a></a>        target, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE</span>
<span id="cb40-22"><a></a>    )</span>
<span id="cb40-23"><a></a>    coins.append(contours[<span class="dv">0</span>])</span>
<span id="cb40-24"><a></a></span>
<span id="cb40-25"><a></a><span class="co"># Draw the outline</span></span>
<span id="cb40-26"><a></a>img <span class="op">=</span> cv2.drawContours(img, coins, <span class="op">-</span><span class="dv">1</span>, color<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">23</span>, <span class="dv">223</span>), thickness<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb40-27"><a></a>imshow(img)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-36-output-1.png" width="322" height="389"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-36-output-2.png" width="365" height="416"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="overlays" class="slide level2 scrollable">
<h2>Overlays</h2>
<!-- https://github.com/austinjoyal/haar-cascade-files/blob/master/haarcascade_eye.xml -->
<!-- https://medium.com/@karanguptagireesh163/to-add-accessories-such-as-sunglasses-or-other-fun-elements-to-the-detected-faces-using-haar-12fdde5b429f -->
<div class="panel-tabset">
<ul id="tabset-11" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-11-1">Python code</a></li><li><a href="#tabset-11-2">Output</a></li><li><a href="#tabset-11-3">Output 2</a></li></ul>
<div class="tab-content">
<div id="tabset-11-1">
<div id="1d5ec1e7" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a></a><span class="im">import</span> cv2</span>
<span id="cb41-2"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb41-3"><a></a></span>
<span id="cb41-4"><a></a><span class="co"># Load the Haar Cascade XML file for face detection</span></span>
<span id="cb41-5"><a></a>face_cascade <span class="op">=</span> cv2.CascadeClassifier(<span class="st">'haarcascade_frontalface_default.xml'</span>)</span>
<span id="cb41-6"><a></a>eye_cascade <span class="op">=</span> cv2.CascadeClassifier(<span class="st">'haarcascade_eye.xml'</span>)</span>
<span id="cb41-7"><a></a></span>
<span id="cb41-8"><a></a><span class="co"># Load the accessory image</span></span>
<span id="cb41-9"><a></a>accessory_image <span class="op">=</span> cv2.imread(<span class="st">'img/ar_overlay.png'</span>, cv2.IMREAD_UNCHANGED)</span>
<span id="cb41-10"><a></a></span>
<span id="cb41-11"><a></a><span class="co"># Initialize the video capture</span></span>
<span id="cb41-12"><a></a>video_capture <span class="op">=</span> cv2.VideoCapture(<span class="dv">0</span>)</span>
<span id="cb41-13"><a></a></span>
<span id="cb41-14"><a></a><span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb41-15"><a></a>    <span class="co"># Read the video frame</span></span>
<span id="cb41-16"><a></a>    ret, frame <span class="op">=</span> video_capture.read()</span>
<span id="cb41-17"><a></a></span>
<span id="cb41-18"><a></a>    <span class="co"># Convert the frame to grayscale</span></span>
<span id="cb41-19"><a></a>    gray <span class="op">=</span> cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</span>
<span id="cb41-20"><a></a></span>
<span id="cb41-21"><a></a>    <span class="co"># Perform face detection</span></span>
<span id="cb41-22"><a></a>    faces <span class="op">=</span> face_cascade.detectMultiScale(gray, scaleFactor<span class="op">=</span><span class="fl">1.1</span>, minNeighbors<span class="op">=</span><span class="dv">5</span>, minSize<span class="op">=</span>(<span class="dv">30</span>, <span class="dv">30</span>))</span>
<span id="cb41-23"><a></a></span>
<span id="cb41-24"><a></a>    <span class="co"># Iterate over detected faces</span></span>
<span id="cb41-25"><a></a>    <span class="cf">for</span> (x, y, w, h) <span class="kw">in</span> faces:</span>
<span id="cb41-26"><a></a>        <span class="co"># Resize the accessory image to fit the face</span></span>
<span id="cb41-27"><a></a>        resized_accessory <span class="op">=</span> cv2.resize(accessory_image, (w, h))</span>
<span id="cb41-28"><a></a>        </span>
<span id="cb41-29"><a></a>        <span class="co"># Calculate the region of interest (ROI) for the accessory</span></span>
<span id="cb41-30"><a></a>        roi <span class="op">=</span> frame[y:y<span class="op">+</span>h, x:x<span class="op">+</span>w]</span>
<span id="cb41-31"><a></a></span>
<span id="cb41-32"><a></a>        <span class="co"># Create a mask for the accessory</span></span>
<span id="cb41-33"><a></a>        accessory_mask <span class="op">=</span> resized_accessory[:, :, <span class="dv">3</span>] <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb41-34"><a></a>        bg_mask <span class="op">=</span> <span class="fl">1.0</span> <span class="op">-</span> accessory_mask</span>
<span id="cb41-35"><a></a></span>
<span id="cb41-36"><a></a>        <span class="co"># Blend the accessory and the frame</span></span>
<span id="cb41-37"><a></a>        accessory_pixels <span class="op">=</span> resized_accessory[:, :, <span class="dv">0</span>:<span class="dv">3</span>]</span>
<span id="cb41-38"><a></a>        bg_pixels <span class="op">=</span> roi[:, :, <span class="dv">0</span>:<span class="dv">3</span>]</span>
<span id="cb41-39"><a></a></span>
<span id="cb41-40"><a></a>        blended_pixels <span class="op">=</span> (accessory_pixels <span class="op">*</span> accessory_mask[:, :, np.newaxis]) <span class="op">+</span> (bg_pixels <span class="op">*</span> bg_mask[:, :, np.newaxis])</span>
<span id="cb41-41"><a></a></span>
<span id="cb41-42"><a></a>        <span class="co"># Replace the ROI with the blended image</span></span>
<span id="cb41-43"><a></a>        frame[y:y<span class="op">+</span>h, x:x<span class="op">+</span>w] <span class="op">=</span> blended_pixels</span>
<span id="cb41-44"><a></a></span>
<span id="cb41-45"><a></a>    <span class="co"># Display the resulting frame</span></span>
<span id="cb41-46"><a></a>    cv2.imshow(<span class="st">'Face Detection with Accessories'</span>, frame)</span>
<span id="cb41-47"><a></a></span>
<span id="cb41-48"><a></a>    <span class="co"># Break the loop if 'q' is pressed</span></span>
<span id="cb41-49"><a></a>    <span class="cf">if</span> cv2.waitKey(<span class="dv">1</span>) <span class="op">&amp;</span> <span class="bn">0xFF</span> <span class="op">==</span> <span class="bu">ord</span>(<span class="st">'q'</span>):</span>
<span id="cb41-50"><a></a>        <span class="cf">break</span></span>
<span id="cb41-51"><a></a></span>
<span id="cb41-52"><a></a><span class="co"># Release the video capture</span></span>
<span id="cb41-53"><a></a>video_capture.release()</span>
<span id="cb41-54"><a></a></span>
<span id="cb41-55"><a></a><span class="co"># Close all OpenCV windows</span></span>
<span id="cb41-56"><a></a>cv2.destroyAllWindows()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-11-2">
<p><img data-src="img/ar_overlay_shot.png"></p>
</div>
<div id="tabset-11-3">
<p><img data-src="img/ar_overlay_shot2.png"></p>
</div>
</div>
</div>
</section>
<section id="yolo-object-recognition" class="slide level2">
<h2>YOLO object recognition</h2>
<!-- https://www.aranacorp.com/en/object-recognition-with-yolo-and-opencv/ -->
<div class="panel-tabset">
<ul id="tabset-12" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-12-1">Initialization</a></li><li><a href="#tabset-12-2">Detection</a></li><li><a href="#tabset-12-3">Result</a></li></ul>
<div class="tab-content">
<div id="tabset-12-1">
<div id="9d8886a2" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb42-2"><a></a></span>
<span id="cb42-3"><a></a><span class="im">import</span> datetime</span>
<span id="cb42-4"><a></a><span class="im">from</span> ultralytics <span class="im">import</span> YOLO</span>
<span id="cb42-5"><a></a><span class="im">import</span> cv2</span>
<span id="cb42-6"><a></a><span class="im">from</span> imutils.video <span class="im">import</span> VideoStream</span>
<span id="cb42-7"><a></a></span>
<span id="cb42-8"><a></a><span class="co"># define some constants</span></span>
<span id="cb42-9"><a></a>CONFIDENCE_THRESHOLD <span class="op">=</span> <span class="fl">0.8</span></span>
<span id="cb42-10"><a></a>GREEN <span class="op">=</span> (<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>)</span>
<span id="cb42-11"><a></a></span>
<span id="cb42-12"><a></a><span class="co"># load the pre-trained YOLOv8n model</span></span>
<span id="cb42-13"><a></a>model <span class="op">=</span> YOLO(<span class="st">"yolov8n.pt"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-12-2">
<div id="2f2450f1" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a></a>frame <span class="op">=</span> cv2.imread(<span class="st">'./img/yolo_test.png'</span>)</span>
<span id="cb43-2"><a></a>detections <span class="op">=</span> model(frame)[<span class="dv">0</span>]</span>
<span id="cb43-3"><a></a><span class="cf">for</span> box <span class="kw">in</span> detections.boxes:</span>
<span id="cb43-4"><a></a>    <span class="co">#extract the label name</span></span>
<span id="cb43-5"><a></a>    label<span class="op">=</span>model.names.get(box.cls.item())</span>
<span id="cb43-6"><a></a>        </span>
<span id="cb43-7"><a></a>    <span class="co"># extract the confidence (i.e., probability) associated with the detection</span></span>
<span id="cb43-8"><a></a>    data<span class="op">=</span>box.data.tolist()[<span class="dv">0</span>]</span>
<span id="cb43-9"><a></a>    confidence <span class="op">=</span> data[<span class="dv">4</span>]</span>
<span id="cb43-10"><a></a></span>
<span id="cb43-11"><a></a>    <span class="co"># filter out weak detections by ensuring the</span></span>
<span id="cb43-12"><a></a>    <span class="co"># confidence is greater than the minimum confidence</span></span>
<span id="cb43-13"><a></a>    <span class="cf">if</span> <span class="bu">float</span>(confidence) <span class="op">&lt;</span> CONFIDENCE_THRESHOLD:</span>
<span id="cb43-14"><a></a>        <span class="cf">continue</span></span>
<span id="cb43-15"><a></a></span>
<span id="cb43-16"><a></a>    <span class="co"># if the confidence is greater than the minimum confidence,</span></span>
<span id="cb43-17"><a></a>    <span class="co"># draw the bounding box on the frame</span></span>
<span id="cb43-18"><a></a>    xmin, ymin, xmax, ymax <span class="op">=</span> <span class="bu">int</span>(data[<span class="dv">0</span>]), <span class="bu">int</span>(data[<span class="dv">1</span>]), <span class="bu">int</span>(data[<span class="dv">2</span>]), <span class="bu">int</span>(data[<span class="dv">3</span>])</span>
<span id="cb43-19"><a></a>    cv2.rectangle(frame, (xmin, ymin) , (xmax, ymax), GREEN, <span class="dv">2</span>)</span>
<span id="cb43-20"><a></a></span>
<span id="cb43-21"><a></a>    <span class="co">#draw confidence and label</span></span>
<span id="cb43-22"><a></a>    y <span class="op">=</span> ymin <span class="op">-</span> <span class="dv">15</span> <span class="cf">if</span> ymin <span class="op">-</span> <span class="dv">15</span> <span class="op">&gt;</span> <span class="dv">15</span> <span class="cf">else</span> ymin <span class="op">+</span> <span class="dv">15</span></span>
<span id="cb43-23"><a></a>    cv2.putText(frame, <span class="st">"</span><span class="sc">{}</span><span class="st"> </span><span class="sc">{:.1f}</span><span class="st">%"</span>.<span class="bu">format</span>(label,<span class="bu">float</span>(confidence<span class="op">*</span><span class="dv">100</span>)), (xmin, y), cv2.FONT_HERSHEY_SIMPLEX, <span class="fl">0.5</span>, GREEN, <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
0: 576x640 4 persons, 12 cars, 41.2ms
Speed: 2.0ms preprocess, 41.2ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)</code></pre>
</div>
</div>
</div>
<div id="tabset-12-3">
<div id="17b3968d" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a></a>plt.imshow(frame)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="lec1_files/figure-revealjs/cell-40-output-1.png" width="485" height="416"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="thank-you" class="slide level2">
<h2>Thank you</h2>



<img data-src="img/entertained.jpg" class="r-stretch"></section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="site_libs/revealjs/plugin/multiplex/socket.io.js"></script>
  <script src="site_libs/revealjs/plugin/multiplex/multiplex.js"></script>
  <script src="site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="site_libs/revealjs/plugin/search/search.js"></script>
  <script src="site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'multiplex': {"url":"https://mplex.vitv.ly","id":"c40463e3600cc67e5d2121505322e229edebf4a5667d7b6ff62412c142bdbe7b","secret":"ef417e8ad09a02004bea46823ac890a6"},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>